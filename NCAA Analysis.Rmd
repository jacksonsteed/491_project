---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
plot(cars)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
```{r}
#import data 
library("tidyverse") 
library("dplyr")
library("ggplot2")
library("readxl")

players2009 <- read_csv("Resources/CollegeBasketballPlayers2009-2021.csv")
players2022 <- read_csv("Resources/CollegeBasketballPlayers2022.csv")
drafted <- read_xlsx("Resources/DraftedPlayers2009-2021.xlsx")

selected_player_data <- players2009 %>% select(player_name, team, pid, ht, pts, ast, stl, blk, treb, Ortg, drtg, year)

summary(selected_player_data)
pts_box <- ggplot(selected_player_data, aes(y = pts), na.rm = TRUE) + geom_boxplot(fill = '#69b3a2', color='black', alpha = 1) + labs(title = "Boxplot of PTS")
pts_hist <- ggplot(selected_player_data, aes(x = pts)) + geom_histogram(binwidth = 1, fill = "yellow", color = "black") + labs(title = "Distribution of PTS", x = "PTS")
plot(selected_player_data[,"Ortg"])
pts_box
pts_hist
team <- selected_player_data[, "team"]
uniqueteam <- unique(team)

max(selected_player_data["Ortg"])
filter(selected_player_data, Ortg > 380)


```

```{r}
#Question: Are high Offensive or Defensive metrics more likly to get you drafted?

#import data 
library("tidyverse") 
library("dplyr")
library("ggplot2")
library("readxl")

#read in csv files
players <- read_csv("Resources/CollegeBasketballPlayers2009-2021.csv")
height <- read_csv("Resources/NewHeights.csv")
unique_team <- read_csv("Resources/unique_team.csv")

#get fields required from players
playerUsed <- select(players, player_name, pick)

combined_ph <- cbind(playerUsed, height)

draftedPlayersHDR <- subset(combined_ph, !is.na(pick))

selected_player_data <- players %>% select(player_name, team, pick, pid, pts, ast, stl, blk, treb, Ortg, drtg, year)
combined_player_data <- cbind(selected_player_data, height)

merged_data <- left_join(combined_player_data, unique_team, by = c("team" = "team")) %>%
  filter(height >= 5.0 & height <= 8.0)

write_csv(merged_data,"FinalData.csv")


```




```{r}
players <- read_csv("Resources/CollegeBasketballPlayers2009-2021.csv")
height <- read_csv("Resources/NewHeights.csv")
unique_team <- read_csv("Resources/unique_team.csv")
selected_player_data <- players %>% select(player_name, team, pid, ht, pts, ast, stl, blk, treb, Ortg, drtg, year)
merged_data <- left_join(selected_player_data, unique_team, by = c("team" = "team"))

set.seed(123) 
kmeans_result <- kmeans(merged_data, centers = 3)
print(kmeans_result$cluster)

ggplot(data, aes(x = variable1, y = variable2, color = cluster)) + 
  geom_point() +
  theme_minimal()
```

```{r}
#Classification algorithm 
install.packages("class")
library(class)


```

```{r}
#Decision Tree
library(rpart) 
library(rpart.plot)
library(randomForest)
library(tidyverse)
library(tidymodels)
library(tidyr)


```

```{r}
#JACKSON __________________________________________________________________________________________________________________________

library("dplyr")
final_data <- read_csv("FinalData.csv")
final_data <- final_data %>% mutate(drafted = NA)
for(i in 1:nrow(final_data)){
  if(is.na(final_data$pick[i])){
    final_data$drafted[i] = 0
  }
  else{
    final_data$drafted[i] = 1
  }
}

write_csv(final_data, "FinalData.csv")

#creating training and testing data:
#split into train and test after sorting
final_data <- final_data %>% arrange(desc(drafted))

drafted_1 <- final_data %>% filter(drafted == 1) %>%
  sample_frac(0.8) # Adjust the fraction as needed for training data

# Sample rows where drafted = 0
drafted_0 <- final_data %>% filter(drafted == 0) %>%
  sample_frac(0.8) # Adjust the fraction as needed for training data

#sample of drafted = 0 but only about 8500
#making a smaller amount of undrafted players to try and balance the data a bit
print(sum(final_data$drafted))
subset_undrafted <- drafted_0 %>% sample_n(1435, replace = FALSE)
mini_undrafted <- subset_undrafted %>% sample_frac(0.8)

small_train <- bind_rows(drafted_1, mini_undrafted)
small_test <- subset_undrafted %>% anti_join(small_train)

write_csv(small_test, "small_test.csv")
write_csv(small_train, "small_train.csv")

# Combine sampled data for training dataset
training_data <- bind_rows(drafted_1, drafted_0)

# Create testing dataset by removing rows used in training dataset
testing_data <- final_data %>% anti_join(training_data) 

write_csv(training_data, "trainingData.csv")
write_csv(testing_data, "testingData.csv")

#benji is cool
#having some fun with neural networks 
library(rpart)
library(randomForest)
library(tidyverse)
library(rpart.plot)
library(keras)

#trouble with this data is that it can guess 0 every time and be 98% accurate because there are so few 1's in the drafted column

training_data <- read_csv("trainingData.csv")
testing_data <- read_csv("testingData.csv")
print(sum(is.na(small_train$pts)))



small_train <- select(small_train, -pick, -player_name, -team, -year)
small_test <- select(small_test, -pick, -player_name, -team, -year, )

preprocess_data <- function(data) {
  data[] <- lapply(data, function(x) {
    if(is.numeric(x)) {
      x[is.infinite(x) | is.nan(x)] <- 0
      x[is.na(x)] <- mean(x, na.rm = TRUE)
      return(x)
    } else {
      return(as.numeric(x))
    }
  })
  return(data)
}

training_data <- preprocess_data(small_train)
testing_data <- preprocess_data(small_test)
training_data <- na.omit(training_data)
# Check for any remaining NAs
sum(is.na(training_data))
sum(is.na(testing_data))

#neural network

X_train <- training_data %>% select(-pid, -drafted) %>%  as.matrix()
y_train <- training_data$drafted

X_test <- testing_data %>% select(-pid, -drafted) %>% as.matrix()
y_test <- testing_data$drafted


model <- keras_model_sequential() %>%
  layer_dense(units = 64, activation = 'relu', input_shape = c(9)) %>%
  layer_dense(units = 1, activation = 'sigmoid')

# Compile the model
model %>% compile(
  loss = 'binary_crossentropy',  
  optimizer = optimizer_adam(),   # use other optimizers like optimizer_sgd() if needed
  metrics = c('accuracy')
)


# Train the model
history <- model %>% fit(
  x = X_train,
  y = y_train,
  epochs = 20,             # Number of training iterations
  batch_size = 32           # Number of samples per gradient update
)

evaluation <- model %>% evaluate(X_test, y_test, verbose = 0)
accuracy <- evaluation[[2]]  # Access the accuracy value from the evaluation result

print(paste("Accuracy:", accuracy))





# Make predictions on the test data
predictions <- model %>% predict(X_test)

# Calculate Mean Absolute Error (MAE)
mae <- mean(abs(predictions - y_test))

```
