---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
plot(cars)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
```{r}
#import data 
library("tidyverse") 
library("dplyr")
library("ggplot2")
library("readxl")

players2009 <- read_csv("Resources/CollegeBasketballPlayers2009-2021.csv")
players2022 <- read_csv("Resources/CollegeBasketballPlayers2022.csv")
drafted <- read_xlsx("Resources/DraftedPlayers2009-2021.xlsx")

selected_player_data <- players2009 %>% select(player_name, team, pid, ht, pts, ast, stl, blk, treb, Ortg, drtg, year)

summary(selected_player_data)
pts_box <- ggplot(selected_player_data, aes(y = pts), na.rm = TRUE) + geom_boxplot(fill = '#69b3a2', color='black', alpha = 1) + labs(title = "Boxplot of PTS")
pts_hist <- ggplot(selected_player_data, aes(x = pts)) + geom_histogram(binwidth = 1, fill = "yellow", color = "black") + labs(title = "Distribution of PTS", x = "PTS")
plot(selected_player_data[,"Ortg"])
pts_box
pts_hist
team <- selected_player_data[, "team"]
uniqueteam <- unique(team)

max(selected_player_data["Ortg"])
filter(selected_player_data, Ortg > 380)


```

```{r}
#Question: Are high Offensive or Defensive metrics more likly to get you drafted?

#import data 
library("tidyverse") 
library("dplyr")
library("ggplot2")
library("readxl")

#read in csv files
players <- read_csv("Resources/CollegeBasketballPlayers2009-2021.csv")
height <- read_csv("Resources/NewHeights.csv")

#get fields required from players
playerUsed <- select(players, player_name, pick)

combined_ph <- cbind(playerUsed, height)

draftedPlayersHDR <- subset(combined_ph, !is.na(pick))


ggplot(draftedPlayersHDR, aes(x = pick, y = ht)) +
  geom_point() +
  labs(title = "Scatter Plot of Height vs Draft Pick", x = "Draft Pick", y = "Height")


num_bins <- 3

# Create equal-width bins for the "pick" column
bins <- cut(draftedPlayersHDR$pick, breaks = seq(min(draftedPlayersHDR$pick), max(draftedPlayersHDR$pick), length.out = num_bins + 1), include.lowest = TRUE)

print(bins)


```

```{r}
library("dplyr")
final_data <- read_csv("FinalData.csv")
final_data <- final_data %>% mutate(drafted = NA)
for(i in 1:nrow(final_data)){
  if(is.na(final_data$pick[i])){
    final_data$drafted[i] = 0
  }
  else{
    final_data$drafted[i] = 1
  }
}

write_csv(final_data, "FinalData.csv")


#split into train and test after sorting
final_data <- final_data %>% arrange(desc(drafted))

drafted_1 <- final_data %>% filter(drafted == 1) %>%
  sample_frac(0.8) # Adjust the fraction as needed for training data

# Sample rows where drafted = 0
drafted_0 <- final_data %>% filter(drafted == 0) %>%
  sample_frac(0.8) # Adjust the fraction as needed for training data

# Combine sampled data for training dataset
training_data <- bind_rows(drafted_1, drafted_0)

# Create testing dataset by removing rows used in training dataset
testing_data <- final_data %>% anti_join(training_data)


```

```{r}
#having some fun with neural networks 
library(rpart)
library(randomForest)
library(tidyverse)
library(rpart.plot)
library(keras)

#trouble with this data is that it can guess 0 every time and be 98% accurate because there are so few 1's in the drafted column

training_data <- read_csv("TrainData.csv")
testing_data <- read_csv("TestData.csv")
print(sum(is.na(training_data$ast)))

na.omit(training)


#neural network

X_train <- training_data %>% select(pts, ast, Ortg) %>% as.matrix()
y_train <- training_data$Ortg

X_test <- testing_data %>% select(pts, ast, Ortg) %>% as.matrix()
y_test <- testing_data$Ortg


model <- keras_model_sequential() %>%
  layer_dense(units = 128, activation = 'relu', input_shape = c(3)) %>%
  layer_dense(units = 64, activation = 'relu') %>%
  layer_dense(units = 1)

# Compile the model
model %>% compile(
  loss = 'mean_squared_error',  
  optimizer = optimizer_adam(lr=0.01)   # use other optimizers like optimizer_sgd() if needed
)


# Train the model
history <- model %>% fit(
  x = X_train,
  y = y_train,
  epochs = 20,             # Number of training iterations
  batch_size = 32           # Number of samples per gradient update
)


# Make predictions on the test data
predictions <- model %>% predict(X_test)

# Calculate Mean Absolute Error (MAE)
mae <- mean(abs(predictions - y_test))

```
